{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10-CNN-Model_Colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/azadkaratas/CIFAR10-CNN-Model/blob/master/CIFAR10_CNN_Model_Colab.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ORYU3qXE-Nfi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**SETTING UP THE COLAB **"
      ]
    },
    {
      "metadata": {
        "id": "e6y8g_-J3OHl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "print(accelerator)\n",
        "!pip install http://download.pytorch.org/whl/cu80/torch-0.4.0-cp36-cp36m-linux_x86_64.whl  torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FkplQw8p-Ilr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**IMPORTING LIBRARIES FOR PyTorch**"
      ]
    },
    {
      "metadata": {
        "id": "rz1lSgrL5hMN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DjZKP15v-C68",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**LOADING DATASETS AND MODEL DECLARATION**"
      ]
    },
    {
      "metadata": {
        "id": "Dg6xLtQd5mEA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# PyTorch CIFAR10 Dataset loading and normalization process [-1, 1]\n",
        "transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=0)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "# Definition of a CNN Model with 5 conv. layers\n",
        "class Net(nn.Module):    \n",
        "    def __init__(self):\n",
        "          super(Net, self).__init__()\n",
        "          # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "          # kernel\n",
        "          self.conv1 = nn.Conv2d(3, 56, 1)\n",
        "          self.conv1_bn = nn.BatchNorm2d(56)\n",
        "          self.conv2 = nn.Conv2d(56, 84, 2)\n",
        "          self.conv2_bn = nn.BatchNorm2d(84)\n",
        "          self.conv3 = nn.Conv2d(84, 128, 2)\n",
        "          self.conv3_bn = nn.BatchNorm2d(128)\n",
        "          self.conv4 = nn.Conv2d(128, 256, 2)\n",
        "          self.conv4_bn = nn.BatchNorm2d(256)\n",
        "          self.conv5 = nn.Conv2d(256, 512, 2)\n",
        "          self.conv5_bn = nn.BatchNorm2d(512)\n",
        "          self.drop = nn.Dropout2d(p=0.2)\n",
        "          \n",
        "          self.fc1 = nn.Linear(4608, 2000)          \n",
        "          self.fc2 = nn.Linear(2000, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1_bn(self.conv1(x))) #Conv -> BN -> ReLu\n",
        "        x = F.relu(self.conv2_bn(self.conv2(x))) #Conv -> BN -> ReLu\n",
        "        x = F.max_pool2d(F.relu(self.conv3_bn(self.conv3(x))),2) #Conv -> BN -> ReLu -> Max Pooling\n",
        "        x = F.max_pool2d(F.relu(self.conv4_bn(self.conv4(x))),2) #Conv -> BN -> ReLu -> Max Pooling \n",
        "        x = F.max_pool2d(F.relu(self.conv5_bn(self.conv5(x))),2) #Conv -> BN -> ReLu -> Max Pooling\n",
        "\n",
        "        x = self.drop(x)\n",
        "        \n",
        "        x = x.view(4, -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Vz4LNIB9_FK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**TRAINING THE MODEL**"
      ]
    },
    {
      "metadata": {
        "id": "yM3CvUx74h3o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Definition of Stochastic Gradient Descent with Momentum as a Loss function and optimizer\n",
        "init_lr = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=init_lr, momentum=0.9)\n",
        "\n",
        "# Training of the network\n",
        "\n",
        "# GPUs are running here\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net.to(device)\n",
        "\n",
        "for epoch in range(1):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "\n",
        "    if epoch == 10:\n",
        "      for param_group in optimizer.param_groups:\n",
        "          param_group['lr'] = 0.0001\n",
        "    elif epoch == 20:\n",
        "      for param_group in optimizer.param_groups:\n",
        "          param_group['lr'] = 0.00001\n",
        "          \n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device) #NEEDED FOR GPU\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "torch.save(net, 'model.pkl')\n",
        "files.download('model.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IuteTKWj96sd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**TESTING THE MODEL**"
      ]
    },
    {
      "metadata": {
        "id": "rsaPH2CZ8r5d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "29448033-2f8c-49ea-8d6a-bc3ba13b2ed6"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#######################################################################\n",
        "################  THIS IS WHERE THE MODEL IS LOADING   ################\n",
        "################                                       ################\n",
        "    \n",
        "#NN_Model = torch.load('model.pkl', map_location='cpu') #.pkl model for CPU computers\n",
        "NN_Model = torch.load('model.pkl')                      #.pkl model for GPU computers\n",
        "\n",
        "################                                       ################\n",
        "################                                       ################\n",
        "#######################################################################\n",
        "\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = NN_Model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
        "\n",
        "#Show score for each class\n",
        "\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = NN_Model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % ( classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 63 %\n",
            "Accuracy of plane : 59 %\n",
            "Accuracy of   car : 80 %\n",
            "Accuracy of  bird : 67 %\n",
            "Accuracy of   cat : 48 %\n",
            "Accuracy of  deer : 31 %\n",
            "Accuracy of   dog : 54 %\n",
            "Accuracy of  frog : 79 %\n",
            "Accuracy of horse : 62 %\n",
            "Accuracy of  ship : 77 %\n",
            "Accuracy of truck : 68 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}